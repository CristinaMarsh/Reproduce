{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoformer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdQl9+49rG0PIimgnMAqER",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristinaMarsh/Reproduce/blob/main/TimeSeries/Autoformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdZEL4-aZFH7",
        "outputId": "43450c6d-a0a5-432a-b4e1-99928ba77a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Autoformer'...\n",
            "remote: Enumerating objects: 242, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 242 (delta 8), reused 0 (delta 0), pack-reused 226\u001b[K\n",
            "Receiving objects: 100% (242/242), 2.11 MiB | 7.82 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/thuml/Autoformer.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\t\t # 查看GPu设备是否可用\n",
        "print(torch.cuda.device_count()) \t\t# 查看GPu设备数量\n",
        "print(torch.cuda.get_device_name())   \t# 查看当前GPu设备名称，默认设备id从0开始\n",
        "print(torch.cuda.current_device())\t\t# 查看当前GPu设备id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ00nOrRZRap",
        "outputId": "1616d8de-1873-4619-99a1-2c7b662b0ed5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "Tesla P100-PCIE-16GB\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() \n",
        "import torch\n",
        "torch.cuda.set_device(0)"
      ],
      "metadata": {
        "id": "6JS9xHPHZXae"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Autoformer/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOpeqryEZdbe",
        "outputId": "6f1f217e-1b12-4d68-9873-1d90b663fcb6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Autoformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = \"/content/drive/My Drive\"\n",
        "sys.path.append(os.path.abspath(py_file_location))"
      ],
      "metadata": {
        "id": "k4hrNZ47Z9OI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.system(\"exp.py\")\n",
        "os.system('utils.py')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az_Yn5g4Vifu",
        "outputId": "2ba93f12-8858-4c50-c766-613c97141c6d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32512"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install reformer_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-_f9CdaWMhA",
        "outputId": "ed659174-b1f6-46cc-8add-1deb57dad344"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting reformer_pytorch\n",
            "  Downloading reformer_pytorch-1.4.4-py3-none-any.whl (16 kB)\n",
            "Collecting product-key-memory\n",
            "  Downloading product_key_memory-0.1.10.tar.gz (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (1.11.0+cu113)\n",
            "Collecting local-attention\n",
            "  Downloading local_attention-1.4.3-py3-none-any.whl (5.0 kB)\n",
            "Collecting axial-positional-embedding>=0.1.0\n",
            "  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->reformer_pytorch) (4.2.0)\n",
            "Building wheels for collected packages: axial-positional-embedding, product-key-memory\n",
            "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2901 sha256=61aa239d9c0029c21a748b11f4b411eb79c0449eaddf3113e3836958d4c655b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/2c/c3/9a1cb267c0d0d9b6eeba7952addb32b17857d1f799690c27a8\n",
            "  Building wheel for product-key-memory (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for product-key-memory: filename=product_key_memory-0.1.10-py3-none-any.whl size=3072 sha256=3c99f56294af1e71fd987f1285aae7d62647d0e895c8310f5b4a7081a2778a06\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/78/51/06648579a50c8e83f24ebfbdfd66462d1b88315a3491deba86\n",
            "Successfully built axial-positional-embedding product-key-memory\n",
            "Installing collected packages: product-key-memory, local-attention, einops, axial-positional-embedding, reformer-pytorch\n",
            "Successfully installed axial-positional-embedding-0.2.1 einops-0.4.1 local-attention-1.4.3 product-key-memory-0.1.10 reformer-pytorch-1.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "from exp.exp_main import Exp_Main#exp stands for experiments\n",
        "import random\n",
        "import numpy as np\n",
        "from utils.tools import dotdict\n",
        "\n",
        "fix_seed = 2021 \n",
        "random.seed(fix_seed)\n",
        "torch.manual_seed(fix_seed)\n",
        "np.random.seed(fix_seed)\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
        "\n",
        "# basic config\n",
        "parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
        "parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')#模型id\n",
        "parser.add_argument('--model', type=str, required=True, default='Autoformer',#选择模型\n",
        "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
        "\n",
        "# data loader\n",
        "parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')#数据类型\n",
        "parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')#数据文件夹路径\n",
        "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')#具体文件\n",
        "parser.add_argument('--features', type=str, default='M',\n",
        "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')#预测类别\n",
        "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')#不太懂 OT好像代表Output Target,要预测的单变量\n",
        "parser.add_argument('--freq', type=str, default='h',\n",
        "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
        "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')#保存模型\n",
        "\n",
        "# forecasting task\n",
        "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')#输入序列长度\n",
        "parser.add_argument('--label_len', type=int, default=48, help='start token length')#这个label_len未完全搞懂\n",
        "parser.add_argument('--pred_len', type=int, default=24, help='prediction sequence length')#输出序列长度\n",
        "\n",
        "# model define\n",
        "parser.add_argument('--bucket_size', type=int, default=4, help='for Reformer')#Reformer专用属性\n",
        "parser.add_argument('--n_hashes', type=int, default=4, help='for Reformer')#Reformer专用属性\n",
        "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')#encoder input size\n",
        "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')#decoder input size\n",
        "parser.add_argument('--c_out', type=int, default=7, help='output size')#输出长度\n",
        "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')#dimension of model\n",
        "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')#num of heads \n",
        "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')#num of encoder layers\n",
        "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')#num of decoder layers\n",
        "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')#dimension of fcn\n",
        "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')#窗口滑动平均数\n",
        "parser.add_argument('--factor', type=int, default=1, help='attn factor')#attn factor不太理解\n",
        "parser.add_argument('--distil', action='store_false',\n",
        "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
        "                    default=True)#是否在encoder里面使用知识蒸馏\n",
        "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')#dropout\n",
        "parser.add_argument('--embed', type=str, default='timeF',\n",
        "                    help='time features encoding, options:[timeF, fixed, learned]')#time features encoding不太能get到\n",
        "parser.add_argument('--activation', type=str, default='gelu', help='activation')#激活函数default=gelu\n",
        "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in encoder')#encoder的output_attention是否输出\n",
        "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')#是否预测未见的未来数据,也就是是否进行推理的意思\n",
        "\n",
        "# optimization\n",
        "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')# num_workers是加载数据(batch)的线程数目\n",
        "parser.add_argument('--itr', type=int, default=2, help='experiments times')#实验次数\n",
        "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')#就是epoch\n",
        "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')#bathsize\n",
        "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')#patience: 当early stop被激活(如发现loss相比上一个epoch训练没有下降)，则经过patience个epoch后停止训练\n",
        "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')#lr\n",
        "parser.add_argument('--des', type=str, default='test', help='exp description')#test\n",
        "parser.add_argument('--loss', type=str, default='mse', help='loss function')#loss is mse\n",
        "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')#adjust learning-rate\n",
        "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)#使用自动混合精度训练\n",
        "\n",
        "# GPU\n",
        "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
        "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
        "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
        "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "args = dotdict()\n",
        "args.target = 'OT'\n",
        "args.des = 'test'\n",
        "args.dropout = 0.05\n",
        "args.num_workers = 10\n",
        "args.gpu = 0\n",
        "args.lradj = 'type1'\n",
        "args.devices = '0'\n",
        "args.use_gpu = True\n",
        "args.use_multi_gpu = False\n",
        "# if args.use_gpu and args.use_multi_gpu: #是否使用多卡的判断\n",
        "#     args.dvices = args.devices.replace(' ', '')\n",
        "#     device_ids = args.devices.split(',')\n",
        "#     args.device_ids = [int(id_) for id_ in device_ids]\n",
        "#     args.gpu = args.device_ids[0]\n",
        "args.freq = 'h'\n",
        "args.checkpoints = './checkpoints/'\n",
        "args.bucket_size = 4\n",
        "args.n_hashes = 4\n",
        "args.is_trainging = True\n",
        "args.root_path = './dataset/ETT-small/'\n",
        "args.data_path ='ETTh1.csv' \n",
        "args.model_id='ETTh1_96_24'\n",
        "args.model = 'Autoformer'\n",
        "args.data = 'ETTh1'\n",
        "args.features = 'M'\n",
        "args.seq_len = 96\n",
        "args.label_len = 48\n",
        "args.pred_len = 24\n",
        "args.e_layers = 2\n",
        "args.d_layers = 1\n",
        "args.n_heads = 8\n",
        "args.factor = 1\n",
        "args.enc_in = 7\n",
        "args.dec_in =7\n",
        "args.c_out = 7\n",
        "args.d_model = 512\n",
        "args.des = 'Exp'\n",
        "args.itr = 1\n",
        "args.d_ff = 2048\n",
        "args.moving_avg = 25\n",
        "args.factor = 1\n",
        "args.distil = True\n",
        "args.output_attention = False\n",
        "args.patience= 3\n",
        "args.learning_rate = 0.0001\n",
        "args.batch_size = 32 \n",
        "args.embed = 'timeF'\n",
        "args.activation = 'gelu'\n",
        "args.use_amp = False\n",
        "args.loss = 'mse'\n",
        "args.train_epochs = 10\n",
        "print('Args in experiment:')\n",
        "print(args)\n",
        "\n",
        "Exp = Exp_Main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxinI9SVZZws",
        "outputId": "195bfacd-50df-4764-abc8-07b95ad8ebe3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Args in experiment:\n",
            "{'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './dataset/ETT-small/', 'data_path': 'ETTh1.csv', 'model_id': 'ETTh1_96_24', 'model': 'Autoformer', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset download\n",
        "#https://github.com/zhouhaoyi/ETDataset/blob/main/ETT-small/ETTh1.csv"
      ],
      "metadata": {
        "id": "3B7VTrl0YSmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Exp_Main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx5T3iPJaLcZ",
        "outputId": "09301cf6-8f05-46d1-906d-3df418323107"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "exp.exp_main.Exp_Main"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "\n",
        "for ii in range(args.itr):#itr就是实验次数可不是epoch，parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
        "    # setting record of experiments\n",
        "    setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
        "        args.model_id,\n",
        "        args.model,\n",
        "        args.data,\n",
        "        args.features,\n",
        "        args.seq_len,\n",
        "        args.label_len,\n",
        "        args.pred_len,\n",
        "        args.d_model,\n",
        "        args.n_heads,\n",
        "        args.e_layers,\n",
        "        args.d_layers,\n",
        "        args.d_ff,\n",
        "        args.factor,\n",
        "        args.embed,\n",
        "        args.distil,\n",
        "        args.des, ii)\n",
        "\n",
        "    exp = Exp(args)  # set experiments\n",
        "    print(1)\n",
        "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "    exp.train(setting)#setting是用来保存模型的名字用的，很细节\n",
        "    print(2)\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(3)"
      ],
      "metadata": {
        "id": "ERV298VCZbzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3900d46a-4fba-4861-da97-9be9531a0d78"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: cuda:0\n",
            "1\n",
            ">>>>>>>start training : ETTh1_96_24_Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 8521\n",
            "val 2857\n",
            "test 2857\n",
            "\titers: 100, epoch: 1 | loss: 0.2662552\n",
            "\tspeed: 0.0889s/iter; left time: 227.6680s\n",
            "\titers: 200, epoch: 1 | loss: 0.3572326\n",
            "\tspeed: 0.0858s/iter; left time: 211.1864s\n",
            "Epoch: 1 cost time: 23.06624937057495\n",
            "Epoch: 1, Steps: 266 | Train Loss: 0.3445070 Vali Loss: 0.5904913 Test Loss: 0.3888729\n",
            "Validation loss decreased (inf --> 0.590491).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 0.2817526\n",
            "\tspeed: 0.2098s/iter; left time: 481.5263s\n",
            "\titers: 200, epoch: 2 | loss: 0.2826247\n",
            "\tspeed: 0.0789s/iter; left time: 173.2865s\n",
            "Epoch: 2 cost time: 21.438267707824707\n",
            "Epoch: 2, Steps: 266 | Train Loss: 0.2816650 Vali Loss: 0.6391841 Test Loss: 0.4220537\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.2212589\n",
            "\tspeed: 0.2058s/iter; left time: 417.5692s\n",
            "\titers: 200, epoch: 3 | loss: 0.2477573\n",
            "\tspeed: 0.0789s/iter; left time: 152.1144s\n",
            "Epoch: 3 cost time: 21.398170232772827\n",
            "Epoch: 3, Steps: 266 | Train Loss: 0.2487682 Vali Loss: 0.7077416 Test Loss: 0.4513546\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.2518848\n",
            "\tspeed: 0.2059s/iter; left time: 363.0557s\n",
            "\titers: 200, epoch: 4 | loss: 0.2480410\n",
            "\tspeed: 0.0788s/iter; left time: 131.1186s\n",
            "Epoch: 4 cost time: 21.400023221969604\n",
            "Epoch: 4, Steps: 266 | Train Loss: 0.2308681 Vali Loss: 0.7428211 Test Loss: 0.4519398\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n",
            "2\n",
            ">>>>>>>testing : ETTh1_96_24_Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 2857\n",
            "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
            "test shape: (2848, 24, 7) (2848, 24, 7)\n",
            "mse:0.3888728618621826, mae:0.42662474513053894\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# custom data: xxx.csv\n",
        "# data features: ['date', ...(other features), target feature]\n",
        "\n",
        "# we take ETTh2 as an example #模仿informer 的 colab example的custom_dataset与predict部分\n",
        "import pandas as pd\n",
        "exp.args.root_path = './dataset/ETT-small/'\n",
        "exp.args.data_path = 'ETTh2.csv'\n",
        "\n",
        "df = pd.read_csv(os.path.join(args.root_path, args.data_path))"
      ],
      "metadata": {
        "id": "1W7UyUAaW9vQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "WrrgSLcCaafp",
        "outputId": "74ec7398-fb57-49dc-ab1a-e26c50c2b4bc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      date       HUFL    HULL       MUFL    MULL    LUFL  \\\n",
              "0      2016-07-01 00:00:00  41.130001  12.481  36.535999   9.355   4.424   \n",
              "1      2016-07-01 01:00:00  37.528000  10.136  33.936001   7.532   4.435   \n",
              "2      2016-07-01 02:00:00  37.946999  11.309  35.330002   9.007   2.100   \n",
              "3      2016-07-01 03:00:00  38.952000  11.895  35.543999   9.436   3.380   \n",
              "4      2016-07-01 04:00:00  38.113998  11.476  35.410000   9.623   2.036   \n",
              "...                    ...        ...     ...        ...     ...     ...   \n",
              "17415  2018-06-26 15:00:00  39.202999  11.392  49.644001  11.929 -10.331   \n",
              "17416  2018-06-26 16:00:00  38.113998  10.974  48.759998  11.366 -10.331   \n",
              "17417  2018-06-26 17:00:00  39.622002  10.974  50.609001  11.661 -11.557   \n",
              "17418  2018-06-26 18:00:00  43.643002  13.403  54.737000  13.778 -10.299   \n",
              "17419  2018-06-26 19:00:00  38.868000  10.052  49.859001  10.669 -11.525   \n",
              "\n",
              "        LULL         OT  \n",
              "0      1.311  38.661999  \n",
              "1      1.215  37.124001  \n",
              "2      0.000  36.465000  \n",
              "3      1.215  33.608501  \n",
              "4      0.000  31.850500  \n",
              "...      ...        ...  \n",
              "17415 -1.258  47.084999  \n",
              "17416 -1.290  48.183498  \n",
              "17417 -1.418  48.183498  \n",
              "17418 -1.418  46.865501  \n",
              "17419 -1.418  45.986500  \n",
              "\n",
              "[17420 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68806d4b-8bdf-40d3-ac13-47f4a6e301b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>HUFL</th>\n",
              "      <th>HULL</th>\n",
              "      <th>MUFL</th>\n",
              "      <th>MULL</th>\n",
              "      <th>LUFL</th>\n",
              "      <th>LULL</th>\n",
              "      <th>OT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01 00:00:00</td>\n",
              "      <td>41.130001</td>\n",
              "      <td>12.481</td>\n",
              "      <td>36.535999</td>\n",
              "      <td>9.355</td>\n",
              "      <td>4.424</td>\n",
              "      <td>1.311</td>\n",
              "      <td>38.661999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-07-01 01:00:00</td>\n",
              "      <td>37.528000</td>\n",
              "      <td>10.136</td>\n",
              "      <td>33.936001</td>\n",
              "      <td>7.532</td>\n",
              "      <td>4.435</td>\n",
              "      <td>1.215</td>\n",
              "      <td>37.124001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-07-01 02:00:00</td>\n",
              "      <td>37.946999</td>\n",
              "      <td>11.309</td>\n",
              "      <td>35.330002</td>\n",
              "      <td>9.007</td>\n",
              "      <td>2.100</td>\n",
              "      <td>0.000</td>\n",
              "      <td>36.465000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-07-01 03:00:00</td>\n",
              "      <td>38.952000</td>\n",
              "      <td>11.895</td>\n",
              "      <td>35.543999</td>\n",
              "      <td>9.436</td>\n",
              "      <td>3.380</td>\n",
              "      <td>1.215</td>\n",
              "      <td>33.608501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-07-01 04:00:00</td>\n",
              "      <td>38.113998</td>\n",
              "      <td>11.476</td>\n",
              "      <td>35.410000</td>\n",
              "      <td>9.623</td>\n",
              "      <td>2.036</td>\n",
              "      <td>0.000</td>\n",
              "      <td>31.850500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17415</th>\n",
              "      <td>2018-06-26 15:00:00</td>\n",
              "      <td>39.202999</td>\n",
              "      <td>11.392</td>\n",
              "      <td>49.644001</td>\n",
              "      <td>11.929</td>\n",
              "      <td>-10.331</td>\n",
              "      <td>-1.258</td>\n",
              "      <td>47.084999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17416</th>\n",
              "      <td>2018-06-26 16:00:00</td>\n",
              "      <td>38.113998</td>\n",
              "      <td>10.974</td>\n",
              "      <td>48.759998</td>\n",
              "      <td>11.366</td>\n",
              "      <td>-10.331</td>\n",
              "      <td>-1.290</td>\n",
              "      <td>48.183498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17417</th>\n",
              "      <td>2018-06-26 17:00:00</td>\n",
              "      <td>39.622002</td>\n",
              "      <td>10.974</td>\n",
              "      <td>50.609001</td>\n",
              "      <td>11.661</td>\n",
              "      <td>-11.557</td>\n",
              "      <td>-1.418</td>\n",
              "      <td>48.183498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17418</th>\n",
              "      <td>2018-06-26 18:00:00</td>\n",
              "      <td>43.643002</td>\n",
              "      <td>13.403</td>\n",
              "      <td>54.737000</td>\n",
              "      <td>13.778</td>\n",
              "      <td>-10.299</td>\n",
              "      <td>-1.418</td>\n",
              "      <td>46.865501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17419</th>\n",
              "      <td>2018-06-26 19:00:00</td>\n",
              "      <td>38.868000</td>\n",
              "      <td>10.052</td>\n",
              "      <td>49.859001</td>\n",
              "      <td>10.669</td>\n",
              "      <td>-11.525</td>\n",
              "      <td>-1.418</td>\n",
              "      <td>45.986500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17420 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68806d4b-8bdf-40d3-ac13-47f4a6e301b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68806d4b-8bdf-40d3-ac13-47f4a6e301b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68806d4b-8bdf-40d3-ac13-47f4a6e301b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(exp.predict(setting,True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDCx9JNUaPHa",
        "outputId": "c1dd4050-ce63-4928-80e0-59c20c027ff1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred 1\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.do_predict = True\n",
        "if args.do_predict:\n",
        "    print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    prediction=exp.predict(setting, True)#data_factory做好了pred里面的batch_size=1的情况，是autoformer在informer基础之上做的\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOYqXNXSZOv1",
        "outputId": "a18e7442-6417-43db-8a6e-119bce244f15"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>>>>>predicting : ETTh1_96_24_Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "pred 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction[-1,:,-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "ylnsIOn5ZcrD",
        "outputId": "5653e18b-3746-4ff5-db0d-a83c3e6daa5f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e6ca5bd458d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "#预测OT\n",
        "plt.plot(prediction[-1,:,-1])#由于prediction.shape是[1,24,7]那么batch只有1 索引只能是0或-1 都是代表batch这一维本身\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "plt.plot(prediction[0,:,-1])#没问题\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "# draw HUFL prediction\n",
        "plt.plot(prediction[0,:,0])#没问题\n",
        "print(prediction.shape)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "GEpMMKzTZTeq",
        "outputId": "0e9daa54-9339-426d-9e82-48dc938462c3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-b309c537d263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#预测OT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#由于prediction.shape是[1,24,7]那么batch只有1 索引只能是0或-1 都是代表batch这一维本身\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bukf2TtpZX2I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}