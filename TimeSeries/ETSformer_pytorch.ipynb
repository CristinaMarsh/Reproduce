{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ETSformer-pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbVpqpuihGOpO3Wm2UsTNh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristinaMarsh/Reproduce/blob/main/TimeSeries/ETSformer_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHoeLdT_bywZ",
        "outputId": "807b7083-678e-47d9-d0a8-f2f99226c719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ETSformer-pytorch'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Total 149 (delta 0), reused 0 (delta 0), pack-reused 149\u001b[K\n",
            "Receiving objects: 100% (149/149), 228.58 KiB | 8.79 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/lucidrains/ETSformer-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install etsformer-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQpimqvzc0Q0",
        "outputId": "195ab37b-60db-4f33-dac6-8263cf1b3c73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting etsformer-pytorch\n",
            "  Downloading ETSformer_pytorch-0.0.16-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from etsformer-pytorch) (1.11.0+cu113)\n",
            "Collecting einops>=0.4\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from etsformer-pytorch) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->etsformer-pytorch) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->etsformer-pytorch) (1.21.6)\n",
            "Installing collected packages: einops, etsformer-pytorch\n",
            "Successfully installed einops-0.4.1 etsformer-pytorch-0.0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from etsformer_pytorch import ETSFormer"
      ],
      "metadata": {
        "id": "qTjnHI3FeBjb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ETSFormer(\n",
        "    time_features = 4,\n",
        "    model_dim = 512,                # in paper they use 512\n",
        "    embed_kernel_size = 3,          # kernel size for 1d conv for input embedding\n",
        "    layers = 2,                     # number of encoder and corresponding decoder layers\n",
        "    heads = 8,                      # number of exponential smoothing attention heads\n",
        "    K = 4,                          # num frequencies with highest amplitude to keep (attend to)\n",
        "    dropout = 0.2                   # dropout (in paper they did 0.2)\n",
        ")\n",
        "\n",
        "timeseries = torch.randn(1, 1024, 4)\n",
        "\n",
        "pred = model(timeseries, num_steps_forecast = 32) # (1, 32, 4) - (batch, num steps forecast, num time features)"
      ],
      "metadata": {
        "id": "KWYzmFpFeEsh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T0EszRHpeJcW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}